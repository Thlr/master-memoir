\chapter{Background and related work}

%This section is organized as follow. First we put Kubernetes in context, in
%light of the advances made in web application development. As we will see,
%despite these adavances in the automation of resource management many
%fundamental questions remain that can only be anwsered by extensive studies on
%computer systems. One such question is the problem of scheduling tasks on
%compute resources, which we briefly present. We end this section by presenting
%the concepts of Batsim which is a distributed system simulator especially well
%suited for studies on scheduling alrogithms.

\section{Studying computer infrastructures} \label{study-computing-infra}

Eventhough this paradigm enabled developing new applications with ease, many
questions remain: what type of infrastructure would be best suited for my
application? Would my application benefit from more cpu cores? How would
different scheduling policies affect my application? Would my batch jobs
compute faster with a different topology? To answer these interrogations one
must conduct studies to experiment with different configurations.\\

Studying an entire computing infrastructure is not an easy feat, first because
every infrastructure is unique. There are as many types of infrastructure as
there are use cases, each having a different vision on efficiency and what
metrics are critical to the system: latency, bandwith, resource availability,
computational power or cost effectiveness (the latter boils down to energy
efficiency). This variety of purposes translates to the type of hardware used
and the topology of the infrastructure. Some systems are centralized like HPC
and Data Centers, others are meant to be used from a distance like Cloud
Computing infrastructures and others are decentralized like Grid Computing,
Volunteer Computing and Peer to Peer computing. There are as many systems as
there are objectives to be achieved.

As a consequence, there are no general tools to study those systems.
Furthermore, as the biggest supercomputers are approaching the exascale
barrier\footnote{https://www.top500.org/news/japan-captures-top500-crown-arm-powered-supercomputer/}
and consist of thousands of nodes with millions of cpu cores (more than 7M for
the new ``Fugaku'' Japanese supercomputer), no human would be capable of
building a general mathematical model that would be accurate enough to predict
the behavior of those systems under varying conditions. Also, interactions
between the various components of those systems may lead to unexpected
behavior\cite{10.1007/978-3-319-09873-9_12} that can hardly be predicted.

In order to extensively experiment on a given system, there are 3 options left
as described in\cite{legrand2015scheduling}: \textit{in vivo}, \textit{in
vitro} and \textit{in silico} studies, which correspond respectively to
experiments on real testbeds, emulation and simulation.  

The next parts are mostly built upon \cite{legrand2015scheduling} and
\cite{casanova:hal-01017319} and are aimed at depicting the current landscape
of experimentation on distributed systems.

\subsubsection{\textit{in vivo} and \textit{in vitro} studies}

The most direct approach to study an infrastructure is running \textit{in vivo}
experiments, that is to say running experiments on a real testbed. This will
produce the most accurate results, however it poses major scalability and
reproducibility issues.

Experiments conducted on real systems may prove difficult to reproduce, as one
must have access to the same system to reiterate it. Even then, changes to the
infrastructure hardware and software environment diminish the chances of
getting the same conditions. One solution to this problem is running \textit{in
vitro} studies, that is to say run an emulation of the system (virtual machines
or a network emulation for example). This resolves the issue of
reproducibility, however the matter of the cost in energy and time remains (if
anything, emulation aggravates these costs).

This cost is exacerbated by the many iterations of a same experiment one must
conduct in order to get statistically significant results. Workloads submitted
by real users can last from hours to months and have substantial costs in
energy: the means required to run them are too great and research to optimize
or simply study these systems can not justify this waste of resources. For all
these reasons scientists resort to simulation to study these computing
infrastructures.

\subsubsection{\textit{in silico} studies, or simulation}

Simulation allows scientists to conduct experiments or thought experiments that
would otherwise not be possible in the real world. One can think of simulations
of the universe, prediction models for the weather or modeling some microbiome
in biology. Computing itself makes no exception and researcher have created
models of computer systems in order to experiment with new scheduling policies,
network topologies or planning for systems capacity, for example. Simulation
dramatically reduces experimentation cost and allows for reproducibility.
Workloads on supercomputers may span weeks or months, whereas a single standard
laptop can simulate this same workload in a matter of seconds or hours,
depending on the simulator. More importantly, other scientists would need
access to the same system the experiment was run on to reproduce the experiment
whereas a simulator supposedly brings the same output regardless of the device
it is run on. The only caveat that remains in terms of reproducibility lies in
the application traces used to run off-line simulations that contain critical
data concerning the application it was generated with.

However, even though simulators theoretically allow for effortlessly
reproducible experiments, the way they are developed sometimes make them hardly
usable at all. Indeed, often simulators are one shot programs made to validate
the models of one scientific project and end up discarded once the paper is
redacted, unusable for any other project unmaintained or plainly unreleased.

TODO; finish this paragraph \& introduce SimGrid in this context

\section{SimGrid}

TODO
To understand Batsim's paradigms and view on simulation, we first need to
present Simgrid's paradigms. As the latter is the framework that Batsim builds
upon, Batsim and Simgrid views on simulation cannot be distinguished.

\section{The scheduling problem}

%In particular, this work is targeted at experimenting with scheduling in a
%distributed system driven by Kubernetes. Here we present a general definition
%of scheduling, and the challenges it tackles.

One notorious problem on the field of distributed systems is the allocation of
queued jobs to available resources.

\begin{displayquote}[][]
	\textbf{schedule} \textit{n.} : A plan for
	performing work or achieving an objective, specifying the order and
	allotted time for each part.
\end{displayquote}

In a general way, scheduling is the concept of allocating available resources
to a set of tasks, organizing them in time and space (the resource space). The
resources can be of any nature, and the tasks independent from each others or
linked together.

In computing the definition remains the same, but with automation in mind.
Schedulers are algorithms that take as an input either a pre-defined workload,
which is a set of jobs  to be executed, or single jobs submitted over time by
users in an unpredictable manner (as it is most often the case with HPC for
example). In the latter case, the jobs are added to a queue managed by the
scheduler. Scheduling is also called batch scheduling or batch processing, as
schedulers allocate batches of jobs at a time. Jobs are allocated on machines,
virtual or physical, with the intent of minimizing the total execution time,
equally distributing resources, minimizing wait time for the user or reducing
energy costs. As these objectives often contradict themselves so schedulers have
to implement compromises or focus on what the user requires from the system.

The scheduler has many factors to keep in mind while trying to be as efficient
as possible, such as:

\begin{itemize}
	\item Resource availability and jobs resource requirements
	\item Link between jobs (some are executed in parallel and need synchronization, some are independent)
	\item Latency between compute resources
	\item Compute resources failures
	\item User defined jobs priority
	\item Machine shutdowns and restarts
	\item Data locality
\end{itemize}

All these elements make scheduling a very intricate problem that is at best
polynomial in complexity, and often NP-hard
(\cite{10.1016/S0022-0000(75)80008-0}, \cite{scheduler-complexity}). In order
to better study the effect of different scheduling policies on a system a
reasearcher team at the LIG have created Batsim which is a versatile
distributed system simulator built on SimGrid and focused on the study of
schedulers.

\section{Batsim}

Batsim\cite{dutot:hal-01333471} is a distributed system simulator built upon
the SimGrid framework. Its main objective is to enable the study of RJMS
without the need to implement a custom simulator, by providing a universal text
based interface. \\

It is entirely deterministic so at to make the studies easily reproducible.
Its event-based models will provide the same results given the same inputs and
decision process. One other way Batsim facilitates reproducibility is through
its user-defined inputs. Unlike other HPC or grid computing simulations that
run on existing application traces, Batsim takes a user defined workload as an
input. As a consequence, the user has no concerns such as intellectual property
on application traces and may provide all his experiments materials and
environment.  Another advantage of this system is that the user can adapt the
workload depending on its needs, to achieve different levels of realism.

Batsim, just like SimGrid, aims at being versatile. The common belief is that
specialization is the key to achieving realistic results, however according to
SimGrid this versatility is all but an obstacle to
accuracy\cite{casanova:hal-01017319}: it is on the contrary the key to their
results which are both scalable and accurate. Batsim computation platforms are
SimGrid platforms meaning that theoretically, they may be as broad as SimGrid
allows it. In reality any SimGrid platform is not a correct Batsim platform.
Because Batsim aims at studying RJMS software, it requires a \textbf{master}
node that will host the decision process. The other hosts (or computational
resources) will have either the roles of \textbf{compute\_node} or
\textbf{storage}. Still, the user may study any topology he wishes using
SimGrid models.

Thanks to its own message interface based on Unix sockets, Batsim is language
agnostic which means that any RJMS can be plugged into it as long as it
implements the interface.

TODO: why batsim?

Because it was developed at the lig and they want to expand its capabilities.
It is language agnostic to very convenient to work with.

\section{Kubernetes in the context of Cloud Computing}

In the early stages of application development, organizations used to run their
services on physical servers. With this direct approach came many challenges
that needed to be coped with manually like resources allocation,
maintainability or scalability. In an attempt to automate this process
developers started using virtual machines which enabled them to run their
services regardless of physical infrastructure while having a better control
over resource allocation.  This led to the concept of containers which takes
the idea of encapsulated applications further than plain virtual machines.

\begin{figure}[h]
	\centering
	\includegraphics[width=\textwidth]{./imgs/container_evolution.png}
	\captionsource{Evolution of application deployment.}{https://kubernetes.io/docs/concepts/overview/what-is-kubernetes/}
	\label{fig:container-evolution}
\end{figure}

Containers can be thought of as lightweight virtual machines. Unlike the
latter, containers share the same kernel with the host machine but still allow
for a very controlled environment to run applications. There are many
benefits to this : separating the development from deployment, portability,
easy resource allocation, breaking large services into smaller micro-services
or support of continuous integration tools (containers greatly facilitate
integration tests).\\

The CNCF\footnote{\url{https://www.cncf.io/}} (Cloud Native Computing
Foundation) was founded in the intent of leveraging the container technology
for an overall better web. In a general way, we now speak of these
containerized and modular applications as cloud native computing :

\textit{``Cloud native technologies empower organizations to build and run
	scalable applications in modern, dynamic environments such as public,
	private, and hybrid clouds. Containers, service meshes, microservices,
	immutable infrastructure, and declarative APIs exemplify this
	approach.}

\textit{These techniques enable loosely coupled systems that
	are resilient, manageable, and observable.  Combined with robust
	automation, they allow engineers to make high-impact changes frequently
	and predictably with minimal toil.``}\footnote{\url{https://github.com/cncf/toc/blob/master/DEFINITION.md}}

Kubernetes\footnote{\url{https://kubernetes.io/}} is the implementation of this
general idea and was anounced at the same time as the CNCF. It aims at
automating of the process of deploying, maintaining and scaling containerized
applications. It is industry grade and is now the de-facto solution for
container orchestration.

\section{Related work}

Simulators are often intentionally very specialized. Some are aimed at specific
domains like peer-to-peer computing simulators (\cite{p2p09-peersim},
\cite{baumgart2009oversim}) or volunteer computing simulators
(\cite{simBA}, \cite{kondo2007simboinc}, \cite{alonso2017combos})

Problems with simulation: often unrealeased simulators, or designed for a
specific project, or short lived (OptorSim) -> This is why Batsim was created.

Simulators specific to platforms: YARNSim, SLURM simulator\footnote{https://github.com/ubccr-slurm-simulator/slurm\_simulator} 

Exemples of papers with custom unreleased simulators: \cite{yabuuchi2019lowlatency} by the same guys who made kubernetes-simulator.\\

When running simulations two primary concerns are accuracy and scalability.
Accuracy is the measure of the bias between the simulated trace of an execution
of an application and its trace as if it were executed on a real system (the
lower it is, the higher the accuracy). Scalability is the ability of the
simulator to compute simulations quickly, or run large scale experiments.\\

list of simulators
\begin{itemize}
	\item SimGrid, GridSim, CloudSim, GroudSim (to cite the most important).
	\item Other simulators in unrelated domains: SimBA (volunteer computing), PeerSim, OverSim (peer to peer), WRENCH (workflows).
	\item HPC simulation: off-line vs on-line
	\item Interconnected networks Simulation: INSEE (environment for interconnected networks), SICOSYS. Aimed to be used with other tools like SIMICS to extend th ecapabilities.
	\item Low level simulation: SIMICS, RSIM and SimOS (multiprocessor systems).
	\item discontinued/old projects: GSSIM, Simbatch
\end{itemize}

Kubernetes simulation: k8-cluster-simulator, joySim.

Related to Batsim in particular: Aléa and Accasim.
